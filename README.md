## ✅ 개요

최근 참여했던 대회의 제출 코드를 요약하여 작성한 것입니다.
<p> 한 데이터셋을 가지고 이진 분류, 다중 클래스 분류를 하는 대회였으며 <p> 타겟값이 불균형하고 수치데이터보다 high Cardinality의 범주형 데이터가 많은 것이 특징이었습니다.   

대회 혹은 데이터를 추정할 수 있는 표기는 모두 변경한 후 업로드했으며
target_1은 이진 분류, target_2는 다중 클래스 분류 타겟을 나타냅니다.<p>

무게, 금액, 일시 등도 기존 피처명이 아니며 제가 임의로 변경한 피처명입니다.

<br>

## ✅ Reference : 
📌 [모델링 구조 참고](https://www.kaggle.com/pourchot/simple-neural-network) <p>
📌 [임베딩 구조 참고](https://www.kaggle.com/abhishek/same-old-entity-embeddings)

<br>

## ✅ 보완할 점:
🔹 모델 구조 : 코드 내 모델은 reference 모델을 활용하여 제작하였는데 만약 keras tuner를 활용하여 적절한 layer 개수, embed_dim, unit 개수 정도라도 찾아봤으면 어땠을까 싶습니다.<p> 다소 과적합되는 걸로 보였는데 처음부터 너무 딥한 모델을 사용했던 것으로 보입니다.<p> 추가적으로 tfa 안에 신기한 기능들이 많은 걸 확인했는데 모두 공부해보고 적절하게 사용해봐야할 것 같습니다.
<p> <br>
🔹 임베딩 : 전체 범주형 피처를 하나의 임베딩 층으로 생성하는 경우와 각 피처별로 하나씩 임베딩 층을 생성하는 경우 모두 진행해봤는데 두 개 경우 모두 장단점이 있는 것 같습니다.<p> 차원축소 알고리즘을 활용하여 3차원으로 줄인 후에 tensorflow playground에서 시각화해보며 피처별로 어떤 차이가 발생하는지 비교해보는 것이 좋을 것 같습니다.<p> 시각화가 어렵다면 각 피처별로 수치를 뽑아내서 비교해보는 것도 좋을 것 같구요. 해당 결과를 가지고 새로운 EDA도 진행되지 않을까 싶습니다.<p>
추가적으로 embed dim을 높일수록 검증 F1 스코어가 높아지는 것을 확인했습니다.
<p> 임계점이 있겠지만 제가 이 부분에서 배운 것은 차원이 커지는 것에 있어서 너무 소극적으로 접근하지 않았나 하는 반성입니다. <p>어떻게든 차원을 줄여서 차원의 저주를 피하고 학습 속도를 줄이려 했었는데 방향이 적절했나 다시 생각해 보게 되었습니다.
<p> <br>
🔹 데이터 선택: embed 신경망과 catboost의 각각의 StratifiedKFold를 다른 seed를 주었으면 어땠을까 생각이 듭니다.<p> 만약 embed의 4번째 폴드를 추출했다면 catboost의 4번째 폴드는 검증 성능이 아주 낮은 반면 나머지 폴드들은 catboost에서 검증 성능이 매우 높은 것으로 발견했습니다. <p>이 부분은 embed 신경망에서 이미 4번째 폴드를 제외한 나머지 폴드의 검증 데이터도 학습했기 때문으로 보입니다.


<br>


## ✅ 마무리:

의아했던 점은 베이스라인 catboost가 embed vector로 변환하여 사용한 catboost보다 더 성능이 좋았다는 것입니다. <p>
아무래도 신경망에 사용했던 데이터와 catboost에 사용했던 데이터가 겹치면서 data leakage 영향도 있었을 것으로 보이고 embedding을 더욱 효율적으로 했다면 embed결과가 훨씬 좋았을 것이라고 예상합니다. <p>

부족한 시간 동안 참여한 대회라.. 더 해보고 싶은 것들이 많았는데 못 해봐서 아쉬움이 남지만 그래도 좋은 경험이었습니다. <p>
