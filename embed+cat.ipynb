{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embed+cat",
      "provenance": [],
      "collapsed_sections": [
        "LNoekJedjZzX"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zP9XTV9V-KW"
      },
      "source": [
        "# Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAvGPAb-KeMp"
      },
      "source": [
        "!pip install tensorflow_addons\n",
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdJi5Q9tV6kU"
      },
      "source": [
        "# *------------ base library ------------*\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# *------------ sklearn ------------*\n",
        "from sklearn.metrics import f1_score, log_loss, precision_score, recall_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.preprocessing import Normalizer, LabelEncoder\n",
        "\n",
        "\n",
        "# *------------tf & keras ------------*\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.metrics import Metric\n",
        "\n",
        "# *------------ Catboost ------------*\n",
        "import catboost as cat\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# *------------default setting & read files ------------*\n",
        "pd.options.display.min_rows=100\n",
        "\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/data/train.csv\", index_col=0)\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/data/test.csv\", index_col=0)\n",
        "ss = pd.read_csv(\"/content/drive/MyDrive/data/submission.csv\")\n",
        "\n",
        "seed=1617\n",
        "def seed_everything(seed):\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "seed_everything(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTvvxBg8HIYI"
      },
      "source": [
        "# Embedding 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV3PD3G-M0f-"
      },
      "source": [
        "# 신고일자 정리 및 수치 데이터 정제\n",
        "def preprocessing(df):\n",
        "    \n",
        "    #날짜 특징 추출\n",
        "    df['date_time'] = pd.to_datetime(df['일시'])\n",
        "    df['day']= df.date_time.dt.day\n",
        "    df['weekday'] = df.date_time.dt.weekday\n",
        "    df['weekend'] = df['weekday'].isin([5,6]).astype(int)\n",
        "\n",
        "    # 수치데이터\n",
        "    df['무게'] = np.log1p(df['무게'])\n",
        "    df['금액'] = np.log1p(df['금액'])\n",
        "    \n",
        "    df.drop(['일시', 'date_time', 'weekday'], axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "train = preprocessing(train)\n",
        "test = preprocessing(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT9hM2osI5G1"
      },
      "source": [
        "cat_features = [x for x in train.columns if x not in [\"target_1\",\"target_2\",'무게','금액']]\n",
        "num_features = ['무게','금액']\n",
        "\n",
        "test.loc[:,'target_1']=-1\n",
        "test.loc[:,'target_2']=-1\n",
        "\n",
        "data=pd.concat([train,test])\n",
        "\n",
        "\n",
        "# 각 피처별 tokenize\n",
        "for feat in cat_features:\n",
        "    lbl_enc = LabelEncoder()\n",
        "    data[feat] = lbl_enc.fit_transform(data[feat].fillna(\"-1\").astype(str).values)\n",
        "\n",
        "# 데이터 분리\n",
        "train = data[data.target_1 !=-1]\n",
        "test = data[data.target_1 ==-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgVInXGGTizd"
      },
      "source": [
        "# callback 정의\n",
        "################# binary -> target_1 #############################\n",
        "\n",
        "ES_bin = tf.keras.callbacks.EarlyStopping(monitor='val_state_full_binary_f1',\n",
        "                                     min_delta=1e-02, patience=5,\n",
        "                                     verbose=0,\n",
        "                                     mode='max',\n",
        "                                     baseline=None, restore_best_weights=True)\n",
        "\n",
        "LRPlateau_bin = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_state_full_binary_f1', \n",
        "                                               factor=0.5, patience=3, verbose=0, min_lr=1e-6,mode='max')\n",
        "\n",
        "dir_name = '/content/drive/MyDrive/data'\n",
        "model_bin_name = \"Embed_special_target_1_classifier\"\n",
        "\n",
        "checkpoint_bin_path = os.path.join(dir_name, model_bin_name+'weights.h5')\n",
        "CP_bin = tf.keras.callbacks.ModelCheckpoint(checkpoint_bin_path, monitor='val_state_full_binary_f1', verbose=False, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "\n",
        "################# multi -> target_2 #############################\n",
        "\n",
        "ES_mul = tf.keras.callbacks.EarlyStopping(monitor='val_state_full_multiclass_f1',\n",
        "                                     min_delta=1e-05, patience=5,\n",
        "                                     verbose=0,\n",
        "                                     mode='max',\n",
        "                                     baseline=None, restore_best_weights=True)\n",
        "\n",
        "LRPlateau_mul = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_state_full_multiclass_f1', \n",
        "                                               factor=0.5, patience=3, verbose=0, min_lr=1e-6, mode='max')\n",
        "\n",
        "dir_name = '/content/drive/MyDrive/data\n",
        "model_mul_name = \"Embed_special_target_2_classifier\"\n",
        "\n",
        "checkpoint_mul_path = os.path.join(dir_name, model_mul_name+'weights.h5')\n",
        "CP_mul = tf.keras.callbacks.ModelCheckpoint(checkpoint_mul_path, monitor='val_state_full_multiclass_f1', verbose=False, save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9nXS06BTrOx"
      },
      "source": [
        "# Ref : https://towardsdatascience.com/f-beta-score-in-keras-part-ii-15f91f07c9a4\n",
        "# custom Total F1 정의\n",
        "\n",
        "class StatefullBinaryFBeta(Metric):\n",
        "  def __init__(self, name='state_full_binary_f1', beta=1, threshold=0.5, epsilon=1e-7, **kwargs): # f1 ==> beta:1\n",
        "    # initializing an object of the super class\n",
        "    super(StatefullBinaryFBeta, self).__init__(name=name, **kwargs)\n",
        "\n",
        "    # initializing state variables\n",
        "    self.tp = self.add_weight(name='tp', initializer='zeros') # initializing true positives \n",
        "    self.actual_positive = self.add_weight(name='fp', initializer='zeros') # initializing actual positives\n",
        "    self.predicted_positive = self.add_weight(name='fn', initializer='zeros') # initializing predicted positives\n",
        "\n",
        "    # initializing other atrributes that wouldn't be changed for every object of this class\n",
        "    self.beta_squared = beta**2 \n",
        "    self.threshold = threshold\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def update_state(self, ytrue, ypred, sample_weight=None):\n",
        "    # casting ytrue and ypred as float dtype\n",
        "    ytrue = tf.cast(ytrue, tf.float32)\n",
        "    ypred = tf.cast(ypred, tf.float32)\n",
        "\n",
        "    # setting values of ypred greater than the set threshold to 1 while those lesser to 0\n",
        "    ypred = tf.cast(tf.greater_equal(ypred, tf.constant(self.threshold)), tf.float32)\n",
        "        \n",
        "    self.tp.assign_add(tf.reduce_sum(ytrue*ypred)) # updating true positives atrribute\n",
        "    self.predicted_positive.assign_add(tf.reduce_sum(ypred)) # updating predicted positive atrribute\n",
        "    self.actual_positive.assign_add(tf.reduce_sum(ytrue)) # updating actual positive atrribute\n",
        "\n",
        "  def result(self):\n",
        "    self.precision = self.tp/(self.predicted_positive+self.epsilon) # calculates precision\n",
        "    self.recall = self.tp/(self.actual_positive+self.epsilon) # calculates recall\n",
        "\n",
        "    # calculating fbeta\n",
        "    self.fb = (1+self.beta_squared)*self.precision*self.recall / (self.beta_squared*self.precision + self.recall + self.epsilon)\n",
        "    \n",
        "    return self.fb\n",
        "\n",
        "  def reset_states(self):\n",
        "    self.tp.assign(0) # resets true positives to zero\n",
        "    self.predicted_positive.assign(0) # resets predicted positives to zero\n",
        "    self.actual_positive.assign(0) # resets actual positives to zero\n",
        "\n",
        "\n",
        "class StatefullMultiClassFBeta(Metric):\n",
        "    \n",
        "    # we create (initialize) the state variables here.\n",
        "    def __init__(self, name='state_full_multiclass_f1', beta=1, n_class=3, average='macro', epsilon=1e-7, **kwargs): # f1 ==> beta:1\n",
        "        # initializing an object of the super class\n",
        "        super(StatefullMultiClassFBeta, self).__init__(name=name, **kwargs)\n",
        "\n",
        "        # initializing state variables\n",
        "        self.tp = self.add_weight(name='tp', shape=(n_class,), initializer='zeros')     # initializing true positives\n",
        "        self.actual_positives = self.add_weight(name='ap', shape=(n_class,), initializer='zeros') # initializing actual positives\n",
        "        self.predicted_positives = self.add_weight(name='pp', shape=(n_class,), initializer='zeros') # initializing predicted positives\n",
        "\n",
        "        # initializing other atrributes that wouldn't be changed for every object of this class\n",
        "        self.beta_squared = beta**2\n",
        "        self.n_class = n_class\n",
        "        self.average = average\n",
        "        self.epsilon = epsilon\n",
        "    \n",
        "    # this method is called at the end of each batch and is used to change (update) the state variables.\n",
        "    def update_state(self, ytrue, ypred, sample_weight=None):\n",
        "        # casting ytrue and ypred as float dtype\n",
        "        ytrue = tf.cast(ytrue, tf.float32)\n",
        "        ypred = tf.cast(ypred, tf.float32)\n",
        "\n",
        "        # finding the maximum probability in ypred\n",
        "        max_prob = tf.reduce_max(ypred, axis=-1, keepdims=True)\n",
        "\n",
        "        # making ypred one hot encoded such that the class with the maximum probability as encoded as 1 while others as 0\n",
        "        ypred = tf.cast(tf.equal(ypred, max_prob), tf.float32)\n",
        "        \n",
        "        self.tp.assign_add(tf.reduce_sum(ytrue*ypred, axis=0)) # updating true positives atrribute\n",
        "        self.predicted_positives.assign_add(tf.reduce_sum(ypred, axis=0)) # updating predicted positives atrribute\n",
        "        self.actual_positives.assign_add(tf.reduce_sum(ytrue, axis=0)) # updating actual positives atrribute\n",
        "    \n",
        "    # this is called at the end of each batch after states variables are updated. It is used to compute and return the metric for each batch.\n",
        "    def result(self):\n",
        "        self.precision = self.tp/(self.predicted_positives+self.epsilon) # calculates precision\n",
        "        self.recall = self.tp/(self.actual_positives+self.epsilon) # calculates recall\n",
        "\n",
        "        # calculating fbeta score\n",
        "        self.fb = (1+self.beta_squared)*self.precision*self.recall / (self.beta_squared*self.precision + self.recall + self.epsilon)\n",
        "\n",
        "        if self.average == 'weighted':\n",
        "            return tf.reduce_sum(self.fb*self.actual_positives / tf.reduce_sum(self.actual_positives))\n",
        "    \n",
        "        elif self.average == 'raw':\n",
        "            return self.fb\n",
        "        \n",
        "        return tf.reduce_mean(self.fb)\n",
        "        \n",
        "    # this is called at the end of each epoch. It is used to clear (reinitialize) the state variables.\n",
        "    def reset_states(self):\n",
        "        self.tp.assign(tf.zeros(self.n_class)) # resets true positives to zero\n",
        "        self.predicted_positives.assign(tf.zeros(self.n_class)) # resets predicted positives to zero\n",
        "        self.actual_positives.assign(tf.zeros(self.n_class)) # resets actual positives to zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTHx6Pt3TktA"
      },
      "source": [
        "## 모델 세팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlAIPYouI52s"
      },
      "source": [
        "모델 후보 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH-UQ_HRRZEb"
      },
      "source": [
        "def create_model(data, cat_features, target, num_features):    \n",
        "    inputs = []\n",
        "    outputs = []\n",
        "\n",
        "    name_scope = [f'feature_{i}' for i in range(len(cat_features))]\n",
        "\n",
        "    for i,c in enumerate(cat_features):\n",
        "        num_unique_values = int(data[c].nunique())\n",
        "        \n",
        "        # embed 차원 결정\n",
        "        if c in ['''cardinaliy 중간 수준 피처''']:\n",
        "            embed_dim = 64\n",
        "        elif c in ['''cardinaliy 큰 피처들''']:\n",
        "            embed_dim = 128\n",
        "        else:\n",
        "            embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n",
        "\n",
        "        inp = layers.Input(shape=(1,))\n",
        "        out = layers.Embedding(num_unique_values + 1, embed_dim, name=name_scope[i])(inp)\n",
        "        out = layers.SpatialDropout1D(0.3)(out)\n",
        "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
        "        inputs.append(inp)\n",
        "        outputs.append(out)\n",
        "\n",
        "    num_inp = layers.Input(shape=(len(num_features),))\n",
        "    inputs.append(num_inp)\n",
        "    outputs.append(num_inp)\n",
        "    \n",
        "    x = layers.Concatenate()(outputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Dense(512, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    if target=='target_2':\n",
        "        y = layers.Dense(3,\n",
        "                         activation='softmax',\n",
        "                         )(x)\n",
        "    \n",
        "    if target=='target_1':\n",
        "        y = layers.Dense(2,\n",
        "                         activation='sigmoid',\n",
        "                         )(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=y)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUl3Gn9aI8vb"
      },
      "source": [
        "모델 후보 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbXG1mXXI94K"
      },
      "source": [
        "def create_model(data, cat_features, target, num_features):    \n",
        "    inputs = []\n",
        "    outputs = []\n",
        "\n",
        "    name_scope = [f'feature_{i}' for i in range(len(cat_features))]\n",
        "\n",
        "    for i,c in enumerate(cat_features):\n",
        "        num_unique_values = int(data[c].nunique())\n",
        "        \n",
        "        # embed 차원 결정\n",
        "        if c in ['''cardinaliy 중간 수준 피처''']:\n",
        "            embed_dim = 64\n",
        "        elif c in ['''cardinaliy 큰 피처들''']:\n",
        "            embed_dim = 128\n",
        "        else:\n",
        "            embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n",
        "\n",
        "        inp = layers.Input(shape=(1,))\n",
        "        out = layers.Embedding(num_unique_values + 1, embed_dim, name=name_scope[i])(inp)\n",
        "        out = layers.SpatialDropout1D(0.3)(out)\n",
        "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
        "        inputs.append(inp)\n",
        "        outputs.append(out)\n",
        "\n",
        "    num_inp = layers.Input(shape=(len(num_features),))\n",
        "    inputs.append(num_inp)\n",
        "    outputs.append(num_inp)\n",
        "    \n",
        "    x = layers.Concatenate()(outputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Dense(1024, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Dense(512, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    #----------- Residual blocks layers ----------------------\n",
        "    x = tfa.layers.WeightNormalization(\n",
        "        layers.Dense(256,\n",
        "                activation ='selu',\n",
        "                kernel_initializer = \"lecun_normal\"))(x)\n",
        "    \n",
        "    drop_out = layers.Dropout(0.3)(x)\n",
        "    x = tfa.layers.WeightNormalization(\n",
        "        layers.Dense(128,\n",
        "                activation='relu',\n",
        "                kernel_initializer = \"he_normal\"))(drop_out) \n",
        "    x = layers.Dropout(0.4)(x)   #layers.Concatenate()([embed, hidden, output]))\n",
        "    x = tfa.layers.WeightNormalization(\n",
        "    layers.Dense(\n",
        "                units = 64, \n",
        "                activation = 'elu',\n",
        "                kernel_initializer = \"lecun_normal\"))(x)\n",
        "\n",
        "\n",
        "    if target=='target_2':\n",
        "        y = layers.Dense(3,\n",
        "                         activation='softmax',\n",
        "                         )(x)\n",
        "    \n",
        "    if target=='target_1':\n",
        "        y = layers.Dense(2,\n",
        "                         activation='sigmoid',\n",
        "                         )(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=y)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ik28UI9URt8"
      },
      "source": [
        "## target_2 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxZUHLSqT31y"
      },
      "source": [
        "oof_mul = np.zeros((train.shape[0],3))\n",
        "target= 'target_2'\n",
        "train_y=train['target_2']\n",
        "train_x=train.drop([\"target_1\",\"target_2\"], axis=1)\n",
        "\n",
        "models_core = []\n",
        "\n",
        "N_FOLDS = 5\n",
        "SEED = seed\n",
        "EPOCH = 100\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train[target])):\n",
        "    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n",
        "\n",
        "    K.clear_session()\n",
        "\n",
        "    X_train_1, X_valid_1, y_train_1, y_valid_1 = train_x.iloc[train_idx], train_x.iloc[valid_idx], train_y.iloc[train_idx], train_y.iloc[valid_idx]\n",
        "\n",
        "\n",
        "    X_train = [X_train_1.loc[:, cat_features].values[:, k] for k in range(X_train_1.loc[:, cat_features].values.shape[1])]+[X_train_1.loc[:,num_features].values]\n",
        "    X_valid = [X_valid_1.loc[:, cat_features].values[:, k] for k in range(X_valid_1.loc[:, cat_features].values.shape[1])]+[X_valid_1.loc[:,num_features].values]\n",
        "\n",
        "    y_train = utils.to_categorical(y_train_1)\n",
        "    y_valid = utils.to_categorical(y_valid_1)\n",
        "\n",
        "    #================= Embedding MODEL training =================\n",
        "    \n",
        "    print(\"\\n-----Embedding model Training-----\\n\")\n",
        "\n",
        "    model = create_model(data, cat_features, target, num_features)\n",
        "\n",
        "    # Metrics Weights 도 있나?\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                       metrics=StatefullMultiClassFBeta(),\n",
        "                       optimizer = tf.keras.optimizers.Adam()\n",
        "                       )\n",
        "    \n",
        "    model.fit(X_train,y_train,\n",
        "               batch_size = 256, \n",
        "               epochs = EPOCH,\n",
        "               validation_data=(X_valid, y_valid),\n",
        "               callbacks=[ES_mul, LRPlateau_mul,CP_mul],\n",
        "              class_weight={0:1.0, 1:3.0, 2: 3.5},\n",
        "               verbose = False)\n",
        "    #============== Embedding Model prediction ============== \n",
        "\n",
        "    pred_mul = model.predict(X_valid) \n",
        "    oof_mul[valid_idx] = pred_mul \n",
        "    \n",
        "    multiclass_score = f1_score(y_true=np.argmax(y_valid, axis=1), y_pred=np.argmax(pred_mul, axis=1), average='macro')\n",
        "\n",
        "    print(f\"target_2 score : {multiclass_score}\")\n",
        "    models_core.append(model)\n",
        "\n",
        "    \n",
        "total_score = f1_score(y_true=train_y, y_pred=np.argmax(oof_mul, axis=1), average='macro')\n",
        "\n",
        "print(f\"\\n=== FINAL target_2 SCORE CONVOLUTION MODEL : {total_score}===\\n\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAHINQISUT8J"
      },
      "source": [
        "## target_1 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TP4i66Tdn_R"
      },
      "source": [
        "oof_bin = np.zeros((train.shape[0],2))\n",
        "target= 'target_1'\n",
        "train_y=train['target_1']\n",
        "train_x=train.drop([\"target_1\",\"target_2\"], axis=1)\n",
        "\n",
        "models_crime = []\n",
        "\n",
        "N_FOLDS = 5\n",
        "SEED = seed\n",
        "EPOCH = 100\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train[target])):\n",
        "    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n",
        "\n",
        "    K.clear_session()\n",
        "\n",
        "    X_train_1, X_valid_1, y_train_1, y_valid_1 = train_x.iloc[train_idx], train_x.iloc[valid_idx], train_y.iloc[train_idx], train_y.iloc[valid_idx]\n",
        "\n",
        "\n",
        "    X_train = [X_train_1.loc[:, cat_features].values[:, k] for k in range(X_train_1.loc[:, cat_features].values.shape[1])]+[X_train_1.loc[:,num_features].values]\n",
        "    X_valid = [X_valid_1.loc[:, cat_features].values[:, k] for k in range(X_valid_1.loc[:, cat_features].values.shape[1])]+[X_valid_1.loc[:,num_features].values]\n",
        "\n",
        "    #X_train = [X_train_1.loc[:, cat_features].values[:, k] for k in range(X_train_1.loc[:, cat_features].values.shape[1])]+[X_train_1.loc[:,num_features]]\n",
        "    #X_valid = [X_valid_1.loc[:, cat_features].values[:, k] for k in range(X_valid_1.loc[:, cat_features].values.shape[1])]+[X_valid_1.loc[:,num_features]]\n",
        "\n",
        "    y_train = utils.to_categorical(y_train_1)\n",
        "    y_valid = utils.to_categorical(y_valid_1)\n",
        "\n",
        "    #================= Embedding MODEL training =========\n",
        "    \n",
        "    print(\"\\n-----Embedding model Training----\\n\")\n",
        "\n",
        "    model = create_model(data, cat_features, target, num_features)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                       metrics=StatefullBinaryFBeta(),\n",
        "                       optimizer = tf.keras.optimizers.Adam()\n",
        "                       )\n",
        "    \n",
        "    model.fit(X_train,y_train,\n",
        "               batch_size = 256, \n",
        "               epochs = EPOCH,\n",
        "               validation_data=(X_valid, y_valid),\n",
        "               callbacks=[ES_bin, LRPlateau_bin,CP_bin],\n",
        "              class_weight={0:1.0, 1:3.0},\n",
        "               verbose = False)\n",
        "    #============== Embedding Model prediction ==========\n",
        " \n",
        "    pred_bin = model.predict(X_valid) \n",
        "    oof_bin[valid_idx] = pred_bin \n",
        "    \n",
        "    binary_score = f1_score(y_true=np.argmax(y_valid, axis=1), y_pred=np.argmax(pred_bin, axis=1), average='binary')\n",
        "\n",
        "    print(f\"target_1 score : {binary_score}\")\n",
        "    models_crime.append(model)\n",
        "    \n",
        "total_score = f1_score(y_true=train_y, y_pred=np.argmax(oof_bin, axis=1), average='binary')\n",
        "\n",
        "print(f\"\\n=== FINAL target_1 SCORE CONVOLUTION MODEL : {total_score}===\\n\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ce7NubiMIb4"
      },
      "source": [
        "# Embedding 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmp_YLvSDpTV"
      },
      "source": [
        "tr_cat = [train.loc[:, cat_features].values[:, k] for k in range(train.loc[:, cat_features].values.shape[1])]\n",
        "tr_cat=tf.convert_to_tensor(tr_cat, dtype=tf.float32)\n",
        "\n",
        "ts_cat = [test.loc[:, cat_features].values[:, k] for k in range(test.loc[:, cat_features].values.shape[1])]\n",
        "ts_cat=tf.convert_to_tensor(ts_cat, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzkvnA8vnSnZ"
      },
      "source": [
        "5개의 fold Embed 결과를 평균 내어 사용하는 코드 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSR_88eLnVa3"
      },
      "source": [
        "# *--------------- target_2 ---------------*\n",
        "# train\n",
        "cat_core_train = pd.DataFrame(index=train.index)\n",
        "cctr = pd.DataFrame(index=train.index)\n",
        "\n",
        "for idx, col in enumerate(cat_features):\n",
        "    for fold in range(5):\n",
        "        emb_fea = models_core[fold].layers[19:38][idx](tr_cat[idx])\n",
        "        emb_np_fea = emb_fea.numpy()\n",
        "        for i in range(emb_np_fea.shape[1]):\n",
        "            if col+f'_{i}' not in cctr.columns:\n",
        "                cctr[col+f'_{i}'] = np.zeros((cctr.shape[0],1))\n",
        "            cctr[col+f'_{i}'] += emb_np_fea[:,i]\n",
        "    cat_core_train[col+f'_{i}']= cctr[col+f'_{i}'].div(5)\n",
        "        \n",
        "    \n",
        "\n",
        "# test\n",
        "cat_core_test = pd.DataFrame(index=test.index)\n",
        "ccts = pd.DataFrame(index=test.index)\n",
        "\n",
        "for idx, col in enumerate(cat_features):\n",
        "    for fold in range(5):\n",
        "        emb_fea = models_core[fold].layers[19:38][idx](ts_cat[idx])\n",
        "        emb_np_fea = emb_fea.numpy()\n",
        "        for i in range(emb_np_fea.shape[1]):\n",
        "            if col+f'_{i}' not in ccts.columns:\n",
        "                ccts[col+f'_{i}'] = np.zeros((ccts.shape[0],1))\n",
        "            ccts[col+f'_{i}'] += emb_np_fea[:,i]\n",
        "    cat_core_test[col+f'_{i}']= ccts[col+f'_{i}'].div(5)\n",
        "\n",
        "display(cat_core_train.head(3))\n",
        "display(cat_core_test.head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3d5LioQnX8F"
      },
      "source": [
        "# *--------------- target_1 ---------------*\n",
        "# train\n",
        "cat_crime_train = pd.DataFrame(index=train.index)\n",
        "cctr = pd.DataFrame(index=train.index)\n",
        "\n",
        "for idx, col in enumerate(cat_features):\n",
        "    for fold in range(5):\n",
        "        emb_fea = models_crime[fold].layers[19:38][idx](tr_cat[idx])\n",
        "        emb_np_fea = emb_fea.numpy()\n",
        "        for i in range(emb_np_fea.shape[1]):\n",
        "            if col+f'_{i}' not in cctr.columns:\n",
        "                cctr[col+f'_{i}'] = np.zeros((cctr.shape[0],1))\n",
        "            cctr[col+f'_{i}'] += emb_np_fea[:,i]\n",
        "    cat_crime_train[col+f'_{i}']= cctr[col+f'_{i}'].div(5)\n",
        "\n",
        "# test\n",
        "cat_crime_test = pd.DataFrame(index=test.index)\n",
        "ccts = pd.DataFrame(index=test.index)\n",
        "\n",
        "for idx, col in enumerate(cat_features):\n",
        "    for fold in range(5):\n",
        "        emb_fea = models_crime[fold].layers[19:38][idx](ts_cat[idx])\n",
        "        emb_np_fea = emb_fea.numpy()\n",
        "        for i in range(emb_np_fea.shape[1]):\n",
        "            if col+f'_{i}' not in ccts.columns:\n",
        "                ccts[col+f'_{i}'] = np.zeros((ccts.shape[0],1))            \n",
        "            ccts[col+f'_{i}'] += emb_np_fea[:,i]\n",
        "    cat_crime_test[col+f'_{i}']= ccts[col+f'_{i}'].div(5)\n",
        "\n",
        "\n",
        "display(cat_crime_train.head(3))\n",
        "display(cat_crime_test.head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ALIM7V9nW4x"
      },
      "source": [
        "5개의 fold Embed 결과 중 가장 높은 점수의 embed를 추출하는 코드 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ceNaC9cXg2A"
      },
      "source": [
        "# *--------------- target_2 ---------------*\n",
        "# train\n",
        "cat_core_train = pd.DataFrame(index=train.index)\n",
        "\n",
        "for idx, col in enumerate(cat_features):\n",
        "    emb_fea = models_core[4].layers[19:38][idx](tr_cat[idx])\n",
        "    emb_np_fea = emb_fea.numpy()\n",
        "    for i in range(emb_np_fea.shape[1]):\n",
        "        cat_core_train[col+f'_{i}']= emb_np_fea[:,i]\n",
        "    \n",
        "\n",
        "# test\n",
        "cat_core_test = pd.DataFrame(index=test.index)\n",
        "\n",
        "for idx, col in enumerate(cat_features):\n",
        "    emb_fea = models_core[4].layers[19:38][idx](ts_cat[idx])\n",
        "    emb_np_fea = emb_fea.numpy()\n",
        "    for i in range(emb_np_fea.shape[1]):\n",
        "        cat_core_test[col+f'_{i}']= emb_np_fea[:,i]\n",
        "\n",
        "display(cat_core_train.head(3))\n",
        "display(cat_core_test.head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOTW1HaqXX-d"
      },
      "source": [
        "# *--------------- target_1 ---------------*\n",
        "# train\n",
        "cat_crime_train = pd.DataFrame(index=train.index)\n",
        "\n",
        "for idx, col in enumerate(cat_features):\n",
        "    emb_fea = models_crime[4].layers[19:38][idx](tr_cat[idx])\n",
        "    emb_np_fea = emb_fea.numpy()\n",
        "    for i in range(emb_np_fea.shape[1]):\n",
        "        cat_crime_train[col+f'_{i}']= emb_np_fea[:,i]\n",
        "\n",
        "# test\n",
        "cat_crime_test = pd.DataFrame(index=test.index)\n",
        "\n",
        "for idx, col in enumerate(cat_features):\n",
        "    emb_fea = models_crime[4].layers[19:38][idx](ts_cat[idx])\n",
        "    emb_np_fea = emb_fea.numpy()\n",
        "    for i in range(emb_np_fea.shape[1]):\n",
        "        cat_crime_test[col+f'_{i}']= emb_np_fea[:,i]\n",
        "\n",
        "\n",
        "display(cat_crime_train.head(3))\n",
        "display(cat_crime_test.head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl2TWOFxXp7h"
      },
      "source": [
        "cat_core_train.to_csv(\"/content/drive/MyDrive/data/embed_cat_core_train_2.csv\", encoding='utf-8', index=True)\n",
        "cat_core_test.to_csv(\"/content/drive/MyDrive/data/embed_cat_core_test_2.csv\", encoding='utf-8', index=True)\n",
        "\n",
        "cat_crime_train.to_csv(\"/content/drive/MyDrive/data/embed_cat_crime_train_2.csv\", encoding='utf-8', index=True)\n",
        "cat_crime_test.to_csv(\"/content/drive/MyDrive/data/embed_cat_crime_test_2.csv\", encoding='utf-8', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zN5K_UcWIHr"
      },
      "source": [
        "# Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9kInCHxORix",
        "outputId": "f19fe685-d55e-45b4-9852-9b772eba36c8"
      },
      "source": [
        "train_y_crime = train['target_2']\n",
        "train_y_core = train['target_1']\n",
        "\n",
        "train_y_crime.shape, train_y_core.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((89619,), (89619,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8U6MbZudq3r"
      },
      "source": [
        "cat_crime_train = pd.read_csv(\"/content/drive/MyDrive/data/embed_cat_crime_train.csv\")\n",
        "cat_crime_test = pd.read_csv(\"/content/drive/MyDrive/data/embed_cat_crime_test.csv\")\n",
        "\n",
        "cat_core_train = pd.read_csv(\"/content/drive/MyDrive/data/embed_cat_core_train.csv\")\n",
        "cat_core_test = pd.read_csv(\"/content/drive/MyDrive/data/embed_cat_core_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugK7PBOhd9hd"
      },
      "source": [
        "# 수치 데이터 추가\n",
        "cat_crime_train['무게']= train['무게']\n",
        "cat_crime_test['무게']= test['무게']\n",
        "\n",
        "cat_crime_train['금액']= train['금액']\n",
        "cat_crime_test['금액']= test['금액']\n",
        "\n",
        "cat_core_train['무게']= train['무게']\n",
        "cat_core_test['무게']= test['무게']\n",
        "\n",
        "cat_core_train['금액']= train['금액']\n",
        "cat_core_test['금액']= test['금액']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciw5q_L1YWZO"
      },
      "source": [
        "cat_core_params = {\n",
        "    'bootstrap_type': 'Poisson',\n",
        "    'custom_metric':'F1',\n",
        "    'random_seed': seed,\n",
        "    'task_type': 'GPU',\n",
        "    'learning_rate': 1e-1,\n",
        "    'n_estimators': 2000,\n",
        "    'auto_class_weights':\"Balanced\"\n",
        "}\n",
        "\n",
        "cat_crime_params = {\n",
        "    'bootstrap_type': 'Poisson',\n",
        "    'custom_metric':'F1',\n",
        "    'random_seed': seed,\n",
        "    'task_type': 'GPU',\n",
        "    'learning_rate': 1e-1,\n",
        "    'n_estimators': 2000,\n",
        "    'auto_class_weights':\"Balanced\"    \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRR5meMleaBk"
      },
      "source": [
        "target_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGmpqMfReavL",
        "outputId": "334b5e75-f34f-41e4-d838-f1f0574f7484"
      },
      "source": [
        "n_fold = 5\n",
        "\n",
        "cat_pred = np.zeros((cat_core_train.shape[0], 1))\n",
        "pred_core_test = pd.DataFrame()\n",
        "feat_core_importance = pd.DataFrame({'fea_name':cat_core_train.columns.to_list()})\n",
        "\n",
        "train_x = cat_core_train\n",
        "test_x= cat_core_test\n",
        "target_y = train_y_core\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skfold.split(train_x, target_y)):\n",
        "    print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "    X_train, X_valid, y_train, y_valid = train_x.iloc[train_idx], train_x.iloc[valid_idx], target_y.iloc[train_idx], target_y.iloc[valid_idx]\n",
        "\n",
        "    model_cat = CatBoostClassifier(**cat_core_params)\n",
        "\n",
        "    model_cat.fit(X_train, y_train, \n",
        "        #cat_features=cat_feats, \n",
        "        eval_set=(X_valid, y_valid), \n",
        "        early_stopping_rounds = 50,\n",
        "\n",
        "        verbose= 100\n",
        "    )\n",
        "  \n",
        "    cat_pred[valid_idx] = model_cat.predict(X_valid)\n",
        "    #pred_core_test[f'{fold}_pred']=model_cat.predict(cat_core_test).reshape(-1,)\n",
        "    feat_core_importance[f'importance_{fold}'] = model_cat.get_feature_importance()\n",
        "    \n",
        "    print('\\nCV f1 Score:', f1_score(y_valid,  cat_pred[valid_idx], average='macro'))\n",
        "    print('\\nCV precision Score:', precision_score(y_valid, cat_pred[valid_idx], average='macro'))\n",
        "    print('CV recall Score:', recall_score(y_valid, cat_pred[valid_idx], average='macro'))\n",
        "\n",
        "print('\\n\\nf1 Score:', f1_score(target_y, cat_pred, average='macro'))\n",
        "print('\\nprecision Score:', precision_score(target_y, cat_pred, average='macro'))\n",
        "print('recall Score:', recall_score(target_y, cat_pred, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------- Fold 0 -----------------\n",
            "\n",
            "0:\tlearn: 1.0778348\ttest: 1.0776663\tbest: 1.0776663 (0)\ttotal: 22.6ms\tremaining: 45.2s\n",
            "100:\tlearn: 0.9195796\ttest: 0.9558806\tbest: 0.9556670 (91)\ttotal: 1.44s\tremaining: 27s\n",
            "200:\tlearn: 0.8873408\ttest: 0.9546067\tbest: 0.9540728 (180)\ttotal: 2.67s\tremaining: 23.9s\n",
            "bestTest = 0.9540728187\n",
            "bestIteration = 180\n",
            "Shrink model to first 181 iterations.\n",
            "\n",
            "CV f1 Score: 0.44918274787774876\n",
            "\n",
            "CV precision Score: 0.4509730149189464\n",
            "CV recall Score: 0.5036852593013844\n",
            "\n",
            "----------------- Fold 1 -----------------\n",
            "\n",
            "0:\tlearn: 1.0772399\ttest: 1.0784745\tbest: 1.0784745 (0)\ttotal: 12.6ms\tremaining: 25.1s\n",
            "100:\tlearn: 0.9175765\ttest: 0.9578853\tbest: 0.9578853 (100)\ttotal: 1.12s\tremaining: 21s\n",
            "bestTest = 0.957805917\n",
            "bestIteration = 113\n",
            "Shrink model to first 114 iterations.\n",
            "\n",
            "CV f1 Score: 0.44620381730976755\n",
            "\n",
            "CV precision Score: 0.4484841477694094\n",
            "CV recall Score: 0.4997967771408665\n",
            "\n",
            "----------------- Fold 2 -----------------\n",
            "\n",
            "0:\tlearn: 1.0780366\ttest: 1.0783365\tbest: 1.0783365 (0)\ttotal: 12.6ms\tremaining: 25.2s\n",
            "100:\tlearn: 0.9203464\ttest: 0.9523421\tbest: 0.9523207 (99)\ttotal: 1.14s\tremaining: 21.5s\n",
            "200:\tlearn: 0.8886215\ttest: 0.9515443\tbest: 0.9509160 (171)\ttotal: 2.31s\tremaining: 20.7s\n",
            "bestTest = 0.9509159895\n",
            "bestIteration = 171\n",
            "Shrink model to first 172 iterations.\n",
            "\n",
            "CV f1 Score: 0.45247992915554786\n",
            "\n",
            "CV precision Score: 0.45356951262370987\n",
            "CV recall Score: 0.5079259844419112\n",
            "\n",
            "----------------- Fold 3 -----------------\n",
            "\n",
            "0:\tlearn: 1.0781692\ttest: 1.0780460\tbest: 1.0780460 (0)\ttotal: 12.9ms\tremaining: 25.9s\n",
            "100:\tlearn: 0.9207679\ttest: 0.9517003\tbest: 0.9516656 (99)\ttotal: 1.18s\tremaining: 22.1s\n",
            "200:\tlearn: 0.8878665\ttest: 0.9504706\tbest: 0.9504706 (200)\ttotal: 2.35s\tremaining: 21.1s\n",
            "bestTest = 0.9504421642\n",
            "bestIteration = 202\n",
            "Shrink model to first 203 iterations.\n",
            "\n",
            "CV f1 Score: 0.4550674977446943\n",
            "\n",
            "CV precision Score: 0.45447626933909113\n",
            "CV recall Score: 0.5088197360821433\n",
            "\n",
            "----------------- Fold 4 -----------------\n",
            "\n",
            "0:\tlearn: 1.0779475\ttest: 1.0775960\tbest: 1.0775960 (0)\ttotal: 13.3ms\tremaining: 26.5s\n",
            "100:\tlearn: 0.9227283\ttest: 0.9413169\tbest: 0.9413169 (100)\ttotal: 1.15s\tremaining: 21.7s\n",
            "200:\tlearn: 0.8910732\ttest: 0.9395114\tbest: 0.9392083 (196)\ttotal: 2.31s\tremaining: 20.7s\n",
            "bestTest = 0.9392083299\n",
            "bestIteration = 196\n",
            "Shrink model to first 197 iterations.\n",
            "\n",
            "CV f1 Score: 0.4685379212015653\n",
            "\n",
            "CV precision Score: 0.464610240765126\n",
            "CV recall Score: 0.526724662154803\n",
            "\n",
            "\n",
            "f1 Score: 0.45427297236802017\n",
            "\n",
            "precision Score: 0.45436764902836363\n",
            "recall Score: 0.5093907557065388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG8V725gevjF"
      },
      "source": [
        "target_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L13HtfN2ewRn",
        "outputId": "ff3468c6-2dcc-4967-c10f-fd1b06eddfe9"
      },
      "source": [
        "n_fold = 5\n",
        "\n",
        "cat_pred = np.zeros((cat_crime_train.shape[0], 1))\n",
        "pred_crime_test = pd.DataFrame()\n",
        "feat_crime_importance = pd.DataFrame({'fea_name':cat_crime_train.columns.to_list()})\n",
        "\n",
        "train_x = cat_crime_train\n",
        "test_x= cat_crime_test\n",
        "target_y = train_y_crime\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skfold.split(train_x, target_y)):\n",
        "    print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "    X_train, X_valid, y_train, y_valid = train_x.iloc[train_idx], train_x.iloc[valid_idx], target_y.iloc[train_idx], target_y.iloc[valid_idx]\n",
        "\n",
        "    model_cat = CatBoostClassifier(**cat_crime_params)\n",
        "\n",
        "    model_cat.fit(X_train, y_train, \n",
        "        #cat_features=cat_feats, \n",
        "        eval_set=(X_valid, y_valid), \n",
        "        early_stopping_rounds = 50,\n",
        "\n",
        "        verbose= 100\n",
        "    )\n",
        "  \n",
        "    cat_pred[valid_idx] = model_cat.predict(X_valid).reshape(-1,1)\n",
        "    #pred_crime_test[f'{fold}_pred']=model_cat.predict(cat_crime_test).reshape(-1,)\n",
        "    \n",
        "    feat_crime_importance[f'importance_{fold}'] = model_cat.get_feature_importance()\n",
        "\n",
        "    print('\\nCV f1 Score:', f1_score(y_valid,  cat_pred[valid_idx], average='binary'))\n",
        "    print('\\nCV precision Score:', precision_score(y_valid, cat_pred[valid_idx], average='binary'))\n",
        "    print('CV recall Score:', recall_score(y_valid, cat_pred[valid_idx], average='binary'))\n",
        "\n",
        "print('\\n\\nf1 Score:', f1_score(target_y, cat_pred, average='binary'))\n",
        "print('\\nprecision Score:', precision_score(target_y, cat_pred, average='binary'))\n",
        "print('recall Score:', recall_score(target_y, cat_pred, average='binary'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------- Fold 0 -----------------\n",
            "\n",
            "0:\tlearn: 0.6668838\ttest: 0.6671397\tbest: 0.6671397 (0)\ttotal: 9.84ms\tremaining: 19.7s\n",
            "100:\tlearn: 0.5201650\ttest: 0.5367427\tbest: 0.5367427 (100)\ttotal: 896ms\tremaining: 16.8s\n",
            "200:\tlearn: 0.5046396\ttest: 0.5341767\tbest: 0.5341599 (193)\ttotal: 1.79s\tremaining: 16s\n",
            "300:\tlearn: 0.4922046\ttest: 0.5333664\tbest: 0.5331743 (259)\ttotal: 2.7s\tremaining: 15.3s\n",
            "bestTest = 0.5331743182\n",
            "bestIteration = 259\n",
            "Shrink model to first 260 iterations.\n",
            "\n",
            "CV f1 Score: 0.5472493942385354\n",
            "\n",
            "CV precision Score: 0.42423820787533045\n",
            "CV recall Score: 0.7707280080889788\n",
            "\n",
            "----------------- Fold 1 -----------------\n",
            "\n",
            "0:\tlearn: 0.6668698\ttest: 0.6675375\tbest: 0.6675375 (0)\ttotal: 9.03ms\tremaining: 18.1s\n",
            "100:\tlearn: 0.5196384\ttest: 0.5374085\tbest: 0.5374085 (100)\ttotal: 871ms\tremaining: 16.4s\n",
            "200:\tlearn: 0.5045493\ttest: 0.5359109\tbest: 0.5357747 (169)\ttotal: 1.76s\tremaining: 15.8s\n",
            "bestTest = 0.5357747291\n",
            "bestIteration = 169\n",
            "Shrink model to first 170 iterations.\n",
            "\n",
            "CV f1 Score: 0.5497045073652641\n",
            "\n",
            "CV precision Score: 0.4222222222222222\n",
            "CV recall Score: 0.7874652514531211\n",
            "\n",
            "----------------- Fold 2 -----------------\n",
            "\n",
            "0:\tlearn: 0.6667527\ttest: 0.6669753\tbest: 0.6669753 (0)\ttotal: 9.26ms\tremaining: 18.5s\n",
            "100:\tlearn: 0.5213010\ttest: 0.5323403\tbest: 0.5323403 (100)\ttotal: 884ms\tremaining: 16.6s\n",
            "200:\tlearn: 0.5062333\ttest: 0.5290962\tbest: 0.5290962 (200)\ttotal: 1.74s\tremaining: 15.6s\n",
            "bestTest = 0.5288167226\n",
            "bestIteration = 216\n",
            "Shrink model to first 217 iterations.\n",
            "\n",
            "CV f1 Score: 0.5521036747736552\n",
            "\n",
            "CV precision Score: 0.42550280476125324\n",
            "CV recall Score: 0.785948951225676\n",
            "\n",
            "----------------- Fold 3 -----------------\n",
            "\n",
            "0:\tlearn: 0.6669825\ttest: 0.6668942\tbest: 0.6668942 (0)\ttotal: 9.89ms\tremaining: 19.8s\n",
            "100:\tlearn: 0.5212525\ttest: 0.5307270\tbest: 0.5307270 (100)\ttotal: 875ms\tremaining: 16.5s\n",
            "200:\tlearn: 0.5068660\ttest: 0.5288735\tbest: 0.5287640 (184)\ttotal: 1.74s\tremaining: 15.6s\n",
            "300:\tlearn: 0.4944373\ttest: 0.5278051\tbest: 0.5277551 (292)\ttotal: 2.62s\tremaining: 14.8s\n",
            "bestTest = 0.5277550731\n",
            "bestIteration = 292\n",
            "Shrink model to first 293 iterations.\n",
            "\n",
            "CV f1 Score: 0.5551523947750362\n",
            "\n",
            "CV precision Score: 0.43299844346964766\n",
            "CV recall Score: 0.7733131159969674\n",
            "\n",
            "----------------- Fold 4 -----------------\n",
            "\n",
            "0:\tlearn: 0.6672547\ttest: 0.6667387\tbest: 0.6667387 (0)\ttotal: 9.79ms\tremaining: 19.6s\n",
            "100:\tlearn: 0.5225408\ttest: 0.5260366\tbest: 0.5260205 (94)\ttotal: 881ms\tremaining: 16.6s\n",
            "200:\tlearn: 0.5076572\ttest: 0.5233547\tbest: 0.5233547 (200)\ttotal: 1.74s\tremaining: 15.5s\n",
            "bestTest = 0.5233214421\n",
            "bestIteration = 211\n",
            "Shrink model to first 212 iterations.\n",
            "\n",
            "CV f1 Score: 0.5581270182992464\n",
            "\n",
            "CV precision Score: 0.4325639599555061\n",
            "CV recall Score: 0.7864004044489383\n",
            "\n",
            "\n",
            "f1 Score: 0.5524518044279123\n",
            "\n",
            "precision Score: 0.4274526082745261\n",
            "recall Score: 0.7807713693575292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmnMAgiejgEx"
      },
      "source": [
        "# 피처중요도"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVpRj2wUlNkU"
      },
      "source": [
        "target_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtoS_97RhiOy"
      },
      "source": [
        "feat_core_importance.sort_values(\"importance_1\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKmw-anCmiJJ"
      },
      "source": [
        "feat_core_drop_list = feat_core_importance.loc[feat_core_importance.apply(lambda row: row[1:].sum()==0, axis=1)].fea_name.to_list()\n",
        "\n",
        "if '금액' not in feat_core_drop_list:\n",
        "    feat_core_drop_list.append('금액')\n",
        "    \n",
        "print('금액' in feat_core_drop_list)\n",
        "print(feat_core_drop_list)\n",
        "print(len(feat_core_drop_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v25Z27xJlO70"
      },
      "source": [
        "target_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_46EXmTChtgq"
      },
      "source": [
        "feat_crime_importance.sort_values(\"importance_1\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy9RaBpymXQn"
      },
      "source": [
        "feat_crime_importance.sort_values(\"importance_1\",)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "U8mBU3vPu_jP",
        "outputId": "754546f2-edeb-4cfb-cdba-1cde04f274a0"
      },
      "source": [
        "feat_crime_importance.loc[feat_crime_importance.apply(lambda row: row[1:].sum()==0, axis=1)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fea_name</th>\n",
              "      <th>importance_0</th>\n",
              "      <th>importance_1</th>\n",
              "      <th>importance_2</th>\n",
              "      <th>importance_3</th>\n",
              "      <th>importance_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [fea_name, importance_0, importance_1, importance_2, importance_3, importance_4]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMG9LdwVfNMw"
      },
      "source": [
        "feat_crime_drop_list = feat_crime_importance.loc[feat_crime_importance.apply(lambda row: row[1:].sum()==0, axis=1)].fea_name.to_list()\n",
        "\n",
        "if '금액' not in feat_crime_drop_list:\n",
        "    feat_crime_drop_list.append('금액')\n",
        "\n",
        "print('금액' in feat_crime_drop_list)\n",
        "print(feat_crime_drop_list)\n",
        "print(len(feat_crime_drop_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNoekJedjZzX"
      },
      "source": [
        "# bad 피처 제거 후 catboost 재실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q70YprUGkIS9"
      },
      "source": [
        "cat_core_train.drop(feat_core_drop_list, axis=1, inplace=True)\n",
        "cat_core_test.drop(feat_core_drop_list, axis=1, inplace=True)\n",
        "\n",
        "cat_crime_train.drop(feat_crime_drop_list, axis=1, inplace=True)\n",
        "cat_crime_test.drop(feat_crime_drop_list, axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdLU8DZRkFmZ"
      },
      "source": [
        "target_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVDnfaOTkGOg",
        "outputId": "29133561-162f-434f-ed83-284047eb53d2"
      },
      "source": [
        "n_fold = 5\n",
        "\n",
        "cat_pred = np.zeros((cat_core_train.shape[0], 1))\n",
        "pred_core_test = pd.DataFrame()\n",
        "feat_core_importance = pd.DataFrame({'fea_name':cat_core_train.columns.to_list()})\n",
        "\n",
        "train_x = cat_core_train\n",
        "target_y = train_y_core\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skfold.split(train_x, target_y)):\n",
        "    print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "    X_train, X_valid, y_train, y_valid = train_x.iloc[train_idx], train_x.iloc[valid_idx], target_y.iloc[train_idx], target_y.iloc[valid_idx]\n",
        "\n",
        "    model_cat = CatBoostClassifier(**cat_core_params)\n",
        "\n",
        "    model_cat.fit(X_train, y_train, \n",
        "        #cat_features=cat_feats, \n",
        "        eval_set=(X_valid, y_valid), \n",
        "        early_stopping_rounds = 50,\n",
        "\n",
        "        verbose= 100\n",
        "    )\n",
        "  \n",
        "    cat_pred[valid_idx] = model_cat.predict(X_valid)\n",
        "    pred_core_test[f'{fold}_pred']=model_cat.predict(cat_core_test).reshape(-1,)\n",
        "    feat_core_importance[f'importance_{fold}'] = model_cat.get_feature_importance()\n",
        "    \n",
        "    print('\\nCV f1 Score:', f1_score(y_valid,  cat_pred[valid_idx], average='macro'))\n",
        "    print('\\nCV precision Score:', precision_score(y_valid, cat_pred[valid_idx], average='macro'))\n",
        "    print('CV recall Score:', recall_score(y_valid, cat_pred[valid_idx], average='macro'))\n",
        "\n",
        "print('\\n\\nf1 Score:', f1_score(target_y, cat_pred, average='macro'))\n",
        "print('\\nprecision Score:', precision_score(target_y, cat_pred, average='macro'))\n",
        "print('recall Score:', recall_score(target_y, cat_pred, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------- Fold 0 -----------------\n",
            "\n",
            "0:\tlearn: 1.0778351\ttest: 1.0776663\tbest: 1.0776663 (0)\ttotal: 17.7ms\tremaining: 35.4s\n",
            "100:\tlearn: 0.9198997\ttest: 0.9546410\tbest: 0.9545356 (91)\ttotal: 1.41s\tremaining: 26.4s\n",
            "200:\tlearn: 0.8880878\ttest: 0.9539131\tbest: 0.9530677 (161)\ttotal: 2.66s\tremaining: 23.8s\n",
            "bestTest = 0.9530677496\n",
            "bestIteration = 161\n",
            "Shrink model to first 162 iterations.\n",
            "\n",
            "CV f1 Score: 0.45041501078430696\n",
            "\n",
            "CV precision Score: 0.45219121844181737\n",
            "CV recall Score: 0.5057396353130962\n",
            "\n",
            "----------------- Fold 1 -----------------\n",
            "\n",
            "0:\tlearn: 1.0772401\ttest: 1.0784746\tbest: 1.0784746 (0)\ttotal: 14.1ms\tremaining: 28.1s\n",
            "100:\tlearn: 0.9184089\ttest: 0.9575585\tbest: 0.9575585 (100)\ttotal: 1.14s\tremaining: 21.5s\n",
            "bestTest = 0.9565721937\n",
            "bestIteration = 140\n",
            "Shrink model to first 141 iterations.\n",
            "\n",
            "CV f1 Score: 0.44707990284687166\n",
            "\n",
            "CV precision Score: 0.4489342929467088\n",
            "CV recall Score: 0.5010540857957663\n",
            "\n",
            "----------------- Fold 2 -----------------\n",
            "\n",
            "0:\tlearn: 1.0780364\ttest: 1.0783365\tbest: 1.0783365 (0)\ttotal: 12.7ms\tremaining: 25.4s\n",
            "100:\tlearn: 0.9209468\ttest: 0.9534121\tbest: 0.9533279 (99)\ttotal: 1.15s\tremaining: 21.7s\n",
            "200:\tlearn: 0.8892463\ttest: 0.9524414\tbest: 0.9515724 (166)\ttotal: 2.32s\tremaining: 20.8s\n",
            "bestTest = 0.9515724216\n",
            "bestIteration = 166\n",
            "Shrink model to first 167 iterations.\n",
            "\n",
            "CV f1 Score: 0.4536599443413198\n",
            "\n",
            "CV precision Score: 0.4545666241880904\n",
            "CV recall Score: 0.5108134194300552\n",
            "\n",
            "----------------- Fold 3 -----------------\n",
            "\n",
            "0:\tlearn: 1.0781691\ttest: 1.0780458\tbest: 1.0780458 (0)\ttotal: 12.4ms\tremaining: 24.8s\n",
            "100:\tlearn: 0.9209029\ttest: 0.9508446\tbest: 0.9507537 (97)\ttotal: 1.13s\tremaining: 21.2s\n",
            "bestTest = 0.950442071\n",
            "bestIteration = 114\n",
            "Shrink model to first 115 iterations.\n",
            "\n",
            "CV f1 Score: 0.45630569581518293\n",
            "\n",
            "CV precision Score: 0.4552316213461441\n",
            "CV recall Score: 0.5113576584650185\n",
            "\n",
            "----------------- Fold 4 -----------------\n",
            "\n",
            "0:\tlearn: 1.0779474\ttest: 1.0775962\tbest: 1.0775962 (0)\ttotal: 14.2ms\tremaining: 28.3s\n",
            "100:\tlearn: 0.9233995\ttest: 0.9408749\tbest: 0.9408749 (100)\ttotal: 1.14s\tremaining: 21.5s\n",
            "200:\tlearn: 0.8921116\ttest: 0.9391488\tbest: 0.9388346 (177)\ttotal: 2.35s\tremaining: 21s\n",
            "bestTest = 0.9388346358\n",
            "bestIteration = 177\n",
            "Shrink model to first 178 iterations.\n",
            "\n",
            "CV f1 Score: 0.4696735601703272\n",
            "\n",
            "CV precision Score: 0.4656454795212333\n",
            "CV recall Score: 0.5279769667253053\n",
            "\n",
            "\n",
            "f1 Score: 0.45538946621137333\n",
            "\n",
            "precision Score: 0.4552470937002265\n",
            "recall Score: 0.5113882379441909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhOE7Hhgkan9"
      },
      "source": [
        "target_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Fd-EY9kblT",
        "outputId": "5c63bfb9-4105-42d1-8b3d-edd2c5ad1420"
      },
      "source": [
        "n_fold = 5\n",
        "\n",
        "cat_pred = np.zeros((cat_crime_train.shape[0], 1))\n",
        "pred_crime_test = pd.DataFrame()\n",
        "feat_crime_importance = pd.DataFrame({'fea_name':cat_crime_train.columns.to_list()})\n",
        "\n",
        "train_x = cat_crime_train\n",
        "target_y = train_y_crime\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skfold.split(train_x, target_y)):\n",
        "    print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
        "    X_train, X_valid, y_train, y_valid = train_x.iloc[train_idx], train_x.iloc[valid_idx], target_y.iloc[train_idx], target_y.iloc[valid_idx]\n",
        "\n",
        "    model_cat = CatBoostClassifier(**cat_crime_params)\n",
        "\n",
        "    model_cat.fit(X_train, y_train, \n",
        "        #cat_features=cat_feats, \n",
        "        eval_set=(X_valid, y_valid), \n",
        "        early_stopping_rounds = 50,\n",
        "\n",
        "        verbose= 100\n",
        "    )\n",
        "  \n",
        "    cat_pred[valid_idx] = model_cat.predict(X_valid).reshape(-1,1)\n",
        "    pred_crime_test[f'{fold}_pred']=model_cat.predict(cat_crime_test).reshape(-1,)\n",
        "    \n",
        "    feat_crime_importance[f'importance_{fold}'] = model_cat.get_feature_importance()\n",
        "\n",
        "    print('\\nCV f1 Score:', f1_score(y_valid,  cat_pred[valid_idx], average='binary'))\n",
        "    print('\\nCV precision Score:', precision_score(y_valid, cat_pred[valid_idx], average='binary'))\n",
        "    print('CV recall Score:', recall_score(y_valid, cat_pred[valid_idx], average='binary'))\n",
        "\n",
        "print('\\n\\nf1 Score:', f1_score(target_y, cat_pred, average='binary'))\n",
        "print('\\nprecision Score:', precision_score(target_y, cat_pred, average='binary'))\n",
        "print('recall Score:', recall_score(target_y, cat_pred, average='binary'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------- Fold 0 -----------------\n",
            "\n",
            "0:\tlearn: 0.6668839\ttest: 0.6671399\tbest: 0.6671399 (0)\ttotal: 9.27ms\tremaining: 18.5s\n",
            "100:\tlearn: 0.5203354\ttest: 0.5366359\tbest: 0.5365319 (95)\ttotal: 861ms\tremaining: 16.2s\n",
            "200:\tlearn: 0.5055614\ttest: 0.5346990\tbest: 0.5346990 (200)\ttotal: 1.7s\tremaining: 15.2s\n",
            "300:\tlearn: 0.4937688\ttest: 0.5341775\tbest: 0.5338523 (274)\ttotal: 2.54s\tremaining: 14.3s\n",
            "bestTest = 0.5338522955\n",
            "bestIteration = 274\n",
            "Shrink model to first 275 iterations.\n",
            "\n",
            "CV f1 Score: 0.54416897878815\n",
            "\n",
            "CV precision Score: 0.4212276569211584\n",
            "CV recall Score: 0.7684529828109201\n",
            "\n",
            "----------------- Fold 1 -----------------\n",
            "\n",
            "0:\tlearn: 0.6668698\ttest: 0.6675375\tbest: 0.6675375 (0)\ttotal: 9.4ms\tremaining: 18.8s\n",
            "100:\tlearn: 0.5201080\ttest: 0.5370282\tbest: 0.5370282 (100)\ttotal: 854ms\tremaining: 16.1s\n",
            "200:\tlearn: 0.5053450\ttest: 0.5354655\tbest: 0.5354600 (175)\ttotal: 1.67s\tremaining: 14.9s\n",
            "bestTest = 0.5352200295\n",
            "bestIteration = 249\n",
            "Shrink model to first 250 iterations.\n",
            "\n",
            "CV f1 Score: 0.5493058027767889\n",
            "\n",
            "CV precision Score: 0.4239593350734991\n",
            "CV recall Score: 0.7798837503158959\n",
            "\n",
            "----------------- Fold 2 -----------------\n",
            "\n",
            "0:\tlearn: 0.6667523\ttest: 0.6669750\tbest: 0.6669750 (0)\ttotal: 9.61ms\tremaining: 19.2s\n",
            "100:\tlearn: 0.5219318\ttest: 0.5321488\tbest: 0.5321488 (100)\ttotal: 858ms\tremaining: 16.1s\n",
            "200:\tlearn: 0.5070505\ttest: 0.5295656\tbest: 0.5295656 (200)\ttotal: 1.67s\tremaining: 14.9s\n",
            "300:\tlearn: 0.4947318\ttest: 0.5289816\tbest: 0.5289384 (295)\ttotal: 2.51s\tremaining: 14.1s\n",
            "bestTest = 0.5288480093\n",
            "bestIteration = 306\n",
            "Shrink model to first 307 iterations.\n",
            "\n",
            "CV f1 Score: 0.5515459324601265\n",
            "\n",
            "CV precision Score: 0.42595650977153865\n",
            "CV recall Score: 0.7821582006570634\n",
            "\n",
            "----------------- Fold 3 -----------------\n",
            "\n",
            "0:\tlearn: 0.6669831\ttest: 0.6668947\tbest: 0.6668947 (0)\ttotal: 9.81ms\tremaining: 19.6s\n",
            "100:\tlearn: 0.5217377\ttest: 0.5311361\tbest: 0.5311361 (100)\ttotal: 881ms\tremaining: 16.6s\n",
            "200:\tlearn: 0.5067342\ttest: 0.5291391\tbest: 0.5289112 (185)\ttotal: 1.74s\tremaining: 15.6s\n",
            "bestTest = 0.5288526915\n",
            "bestIteration = 241\n",
            "Shrink model to first 242 iterations.\n",
            "\n",
            "CV f1 Score: 0.5531722327812472\n",
            "\n",
            "CV precision Score: 0.43090806542583193\n",
            "CV recall Score: 0.7723022491786707\n",
            "\n",
            "----------------- Fold 4 -----------------\n",
            "\n",
            "0:\tlearn: 0.6672547\ttest: 0.6667388\tbest: 0.6667388 (0)\ttotal: 16.2ms\tremaining: 32.4s\n",
            "100:\tlearn: 0.5232920\ttest: 0.5259309\tbest: 0.5259292 (99)\ttotal: 860ms\tremaining: 16.2s\n",
            "200:\tlearn: 0.5083968\ttest: 0.5227821\tbest: 0.5227821 (200)\ttotal: 1.68s\tremaining: 15s\n",
            "300:\tlearn: 0.4959684\ttest: 0.5225789\tbest: 0.5224529 (295)\ttotal: 2.51s\tremaining: 14.1s\n",
            "bestTest = 0.5224529352\n",
            "bestIteration = 295\n",
            "Shrink model to first 296 iterations.\n",
            "\n",
            "CV f1 Score: 0.5586652314316469\n",
            "\n",
            "CV precision Score: 0.4329810901001112\n",
            "CV recall Score: 0.7871587462082912\n",
            "\n",
            "\n",
            "f1 Score: 0.5513621952748571\n",
            "\n",
            "precision Score: 0.42698218942462407\n",
            "recall Score: 0.7779912045695799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rzLJWQAO5gT"
      },
      "source": [
        "#제출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_V-WiBOaZz5"
      },
      "source": [
        "ss.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GACchyjpO6IZ"
      },
      "source": [
        "ss['target_2']= pred_core_test.T.mode().rename(index={0:\"pred_mode\"}).T['pred_mode']\n",
        "ss['target_1']= pred_crime_test.T.mode().rename(index={0:\"pred_mode\"}).T['pred_mode']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}